# 字符验证码破解

## 前言

如果MNIST数据集是计算机视觉届的“Hello, World”的话，那么破解字符验证码就是计算机视觉届的99乘法表。目前市场上的字符验证码一般是由大小写英文字母和阿拉伯数字组成，最常见的是4个字符，下面我们来一步步解析如何使用前面介绍的知识一步步破解字符验证码，尝试了近10个不同得网站，平均精度能够控制到99%上下。在文章中出于法律问题的原因，并不会列举破解了哪些公司的验证码。

## 1. 综述

破解一个网站的验证码主要分成以下步骤：

1. 数据爬取和标注；
2. 模型搭建和数据预处理；
3. 合成数据和迁移学习；
4. n折数据交叉清洗；
5. 模型fine-tune。

以上的算法的开发环境我使用的是python 2.7.6 + keras 2.1.2 \(TensorFlow做后端\)，若使用截止最新的版本 python 3.7.0及keras 2.2.0，代码需要进行语法的微调后便可运行。

### 1.1 数据爬取和标注

破解一个网站的验证码，标注数据样本是必不可少的一步。为了减轻标注数据的成本，我一般标注11500张数据，其中10000张作为训练集，1000张作为测试集，500张作为验证集。标注数据可以采用亚马逊等平台提供的众包工具，当然不怕浪费时间的话也可以自己标。注意外包出去的验证码由于各种各样的原因导致存在标注错误的情况，一般用户常犯两种错误：

1. 近似字符的标注错误，例如‘U’和‘V’等，我一般叫这种错误为**眼花错误**；
2. 键盘临近字符敲错，例如‘S’和‘D’等，我一般叫做**手抖错误**。

清理训练集错误数据是将模型能力提升至接近100%的至关重要的一步，我们在1.4节介绍如何使用模型帮助我们清理训练集数据。但是对于验证集我建议还是自己手动清理，原因有三点：1. 测试集加验证集数据并不多，一般两三个小时便可手动清理完毕；2. 清理的过程中，我们顺便观察验证码的样式，为下一步迁移学习积累知识；3. 1.4节使用的n折数据交叉清洗的方法并不能保证100%清理干净。

### 1.2 模型搭建

我一般使用CNN+GRU+CTC损失的网络结构，这也是OCR场景中最流行的框架结构，其中我在第一章进行了介绍，GRU和CTC在第二章进行了介绍，算法详解参考具体章节的内容。

#### 1.2.1 CNN

一般验证码的场景比较简单，使用简单的VGG模式便可以解决。即

```
m\times(n\times(conv\_33)+max\_pooling)
```

其中n是根据验证码的复杂程度决定，一般复杂程度表示的是验证码的干扰因素的多少，我们在1.3节会手动合成样本，验证码的复杂度你会在进行这一过程时深刻的感受到。一般n为2-4之间。

m的大小取决于验证码最短边的长度，我们在第一章介绍过，每次pooling便进行一次降采样，此时Feature Map的大小会减半。在输入RNN之前，对于验证码这种简单的场景，最后一层的Feature Map的尺寸在5-10之间是一个优先选择的尺寸。目前市场上的主流验证码的最短边（高度）一般在30-60之间，所以m优先取值2或者3。

#### 1.2.2 GRU和CTC

在经过CNN得到Feature Map之后，我们需要将Feature Map展开成一个向量，然后经过一个全连接的编码之后作为GRU的输入。全连接我一般使用的节点数目为32。

关于GRU和CTC这一部分介绍的并不多，在目前的所有网站中，我使用的均是两层双向GRU结构，其中隐节点数量为128。

最后使用CTC构造损失函数。要非常注意的一点是Keras封装的decode函数存在内存泄漏的问题，长时间训练或者测试时会产生内存不足的问题。这里我根据单独重现了CTC的Beam Search函数，读者可以网上自行搜索相关源码。

#### 1.2.3 分类函数





